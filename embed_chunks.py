# embed_chunks.py

"""
Documentation:

Dependencies:
The script requires os, qdrant_client, sentence_transformers, json, dotenv, and argparse.

Key Functions:
This script specifically handles the embedding of raw text chunks generated by ingest.py.

    1. Data Loading and Preparation
    load_chunks(file_path): Reads a list of raw text chunks from a specified input JSON file (the standard output format of ingest.py).

    2. embed_chunks(chunks, collection_name)
    This function manages the vectorization and upload process:
    Model Consistency: It uses the standard 'all-MiniLM-L6-v2' Sentence Transformer model, matching the model used in embed.py and the search scripts.
    Qdrant Collection: It uploads vectors to the collection named "chunks_collection" by default. This collection is kept separate from the claim-based vector store (knowledge_base).
    Vectorization: It encodes the raw text from the chunks list.
    Point Preparation: It creates Qdrant points (models.PointStruct), where:
    The ID is the sequential index (i) of the chunk.
    The Payload contains the "chunk_text" and a hardcoded "source_ref" placeholder (which should ideally be dynamic).

    3. Execution (if __name__ == "__main__":)
    It takes the path to the JSON chunk file as a required command-line argument.
    It loads the chunks and initiates the embedding process into the dedicated chunk collection.
"""

import os
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
import json
import dotenv
import argparse

dotenv.load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

def load_chunks(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)
    
def embed_chunks(chunks, collection_name="chunks_collection"):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
    client.recreate_collection(
        collection_name=collection_name,
        vectors_config=models.VectorParams(size=model.get_sentence_embedding_dimension(), distance=models.Distance.COSINE)
    )
    vectors = model.encode([chunk for chunk in chunks], show_progress_bar=True).tolist()
    points = [
        models.PointStruct(
            id=i,
            vector=vectors[i],
            payload={
                "chunk_text": chunks[i],
                "source_ref": "your_source_file.json"
            }
        )
        for i in range(len(chunks))
    ]

    client.upsert(collection_name=collection_name, wait=True, points=points)
    print(f"Uploaded {len(chunks)} chunks to Qdrant")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Embed chunks from a JSON file into Qdrant.")
    parser.add_argument("file_path", help="Path to the chunk JSON file.")
    args = parser.parse_args()

    chunks = load_chunks(args.file_path)
    embed_chunks(chunks)
